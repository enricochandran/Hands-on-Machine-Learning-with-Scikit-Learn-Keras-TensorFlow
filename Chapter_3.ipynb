{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urcwT75on-Ly"
      },
      "source": [
        "# **MNIST**\n",
        "\n",
        "Dataset MNIST adalah standar dalam *Machine Learning* untuk tugas klasifikasi. Scikit-Learn menyediakan fungsi untuk mengunduh dataset populer ini.\n",
        "Dataset yang dimuat oleh Scikit-Learn umumnya memiliki struktur kamus dengan kunci seperti:\n",
        "* `DESCR`: Deskripsi dataset.\n",
        "* `data`: Array dengan satu baris per instansi dan satu kolom per fitur.\n",
        "* `target`: Array dengan label.\n",
        "\n",
        "Contoh pengambilan dataset MNIST:\n",
        "```python\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "# mnist.keys() akan menampilkan dict_keys(['data', 'target', 'feature_names', 'DESCR', 'details', 'categories', 'url'])\n",
        "```\n",
        "Dataset ini berisi 70.000 gambar, masing-masing dengan 784 fitur. Ini karena setiap gambar berukuran $28 \\times 28$ piksel, dan setiap fitur merepresentasikan intensitas piksel (0 untuk putih, 255 untuk hitam).\n",
        "Contoh menampilkan salah satu digit:\n",
        "```python\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X, y = mnist[\"data\"], mnist[\"target\"]\n",
        "# X.shape adalah (70000, 784), y.shape adalah (70000,)\n",
        "some_digit = X.iloc[0] # Menggunakan .iloc karena X adalah DataFrame\n",
        "some_digit_image = some_digit.values.reshape(28, 28) # .values untuk mengubah Series ke array numpy\n",
        "\n",
        "plt.imshow(some_digit_image, cmap=\"binary\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "# y[0] akan menampilkan '5'\n",
        "```\n",
        "Label dalam dataset ini awalnya berupa *string*, sehingga perlu diubah ke integer karena sebagian besar algoritma ML mengharapkan angka.\n",
        "```python\n",
        "y = y.astype(np.uint8)\n",
        "```\n",
        "Dataset MNIST sudah dibagi menjadi *training set* (60.000 gambar pertama) dan *test set* (10.000 gambar terakhir). *Training set* sudah diacak (shuffled), yang baik untuk memastikan *cross-validation folds* serupa dan algoritma tidak terpengaruh oleh urutan instansi pelatihan.\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
        "```\n",
        "\n",
        "**Melatih *Binary Classifier***\n",
        "Untuk menyederhanakan masalah, awalnya kita hanya akan mencoba mengidentifikasi satu digit, misalnya angka 5 (sebagai \"detektor-5\"). Ini adalah contoh *binary classifier* yang membedakan dua kelas: 5 dan bukan-5.\n",
        "Target vektor untuk tugas ini dibuat:\n",
        "```python\n",
        "y_train_5 = (y_train == 5) # True untuk semua 5, False untuk digit lain\n",
        "y_test_5 = (y_test == 5)\n",
        "```\n",
        "`SGDClassifier` (Stochastic Gradient Descent) dari Scikit-Learn adalah pilihan yang baik untuk memulai karena efisien dalam menangani dataset sangat besar, sebagian karena ia memproses instansi pelatihan secara independen.\n",
        "Melatih `SGDClassifier`:\n",
        "```python\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42) # random_state diatur untuk hasil yang dapat direproduksi\n",
        "sgd_clf.fit(X_train, y_train_5)\n",
        "```\n",
        "Contoh prediksi:\n",
        "```python\n",
        "# sgd_clf.predict([some_digit]) # Akan menampilkan array([ True])\n",
        "```\n",
        "\n",
        "**Ukuran Performa (*Performance Measures*)**\n",
        "Mengevaluasi *classifier* seringkali lebih rumit daripada *regressor*.\n",
        "\n",
        "* **Mengukur Akurasi Menggunakan *Cross-Validation***:\n",
        "    Seperti di Bab 2, *cross-validation* adalah cara yang baik untuk mengevaluasi model.\n",
        "    Implementasi *cross-validation* secara manual:\n",
        "    ```python\n",
        "    from sklearn.model_selection import StratifiedKFold\n",
        "    from sklearn.base import clone\n",
        "\n",
        "    skfolds = StratifiedKFold(n_splits=3, random_state=42) # StratifiedKFold melakukan stratified sampling\n",
        "\n",
        "    for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
        "        clone_clf = clone(sgd_clf)\n",
        "        X_train_folds = X_train.iloc[train_index]\n",
        "        y_train_folds = y_train_5.iloc[train_index]\n",
        "        X_test_fold = X_train.iloc[test_index]\n",
        "        y_test_fold = y_train_5.iloc[test_index]\n",
        "\n",
        "        clone_clf.fit(X_train_folds, y_train_folds)\n",
        "        y_pred = clone_clf.predict(X_test_fold)\n",
        "        n_correct = sum(y_pred == y_test_fold)\n",
        "        # print(n_correct / len(y_pred)) # Akan mencetak 0.9502, 0.96565, dan 0.96495\n",
        "    ```\n",
        "    Menggunakan `cross_val_score()`:\n",
        "    ```python\n",
        "    from sklearn.model_selection import cross_val_score\n",
        "\n",
        "    # cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\") # Akan menghasilkan array sekitar [0.96355, 0.93795, 0.95615]\n",
        "    ```\n",
        "    Akurasi di atas 93% terlihat bagus, namun ini bisa menyesatkan untuk *skewed datasets* (ketika satu kelas jauh lebih sering daripada yang lain). Contohnya, *classifier* \"Never5Classifier\" yang selalu memprediksi \"bukan-5\" akan memiliki akurasi di atas 90% karena hanya sekitar 10% gambar yang merupakan angka 5. Ini menunjukkan mengapa akurasi bukan metrik performa yang utama untuk *classifier*.\n",
        "\n",
        "* ***Confusion Matrix***:\n",
        "    Cara yang lebih baik untuk mengevaluasi *classifier* adalah dengan melihat *confusion matrix*. Ini menghitung berapa kali instansi kelas A diklasifikasikan sebagai kelas B.\n",
        "    Untuk menghitung *confusion matrix*, pertama-tama kita perlu serangkaian prediksi. Menggunakan `cross_val_predict()` akan memberikan prediksi \"bersih\" untuk setiap instansi di *training set*.\n",
        "    ```python\n",
        "    from sklearn.model_selection import cross_val_predict\n",
        "    from sklearn.metrics import confusion_matrix\n",
        "\n",
        "    y_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)\n",
        "    # confusion_matrix(y_train_5, y_train_pred) # Akan menghasilkan array seperti [[53057, 1522], [1325, 4096]]\n",
        "    ```\n",
        "    Setiap baris dalam *confusion matrix* merepresentasikan kelas aktual, dan setiap kolom merepresentasikan kelas yang diprediksi.\n",
        "    * **True Negatives (TN):** Gambar bukan-5 yang diklasifikasikan dengan benar sebagai bukan-5.\n",
        "    * **False Positives (FP):** Gambar bukan-5 yang salah diklasifikasikan sebagai 5.\n",
        "    * **False Negatives (FN):** Gambar 5 yang salah diklasifikasikan sebagai bukan-5.\n",
        "    * **True Positives (TP):** Gambar 5 yang diklasifikasikan dengan benar sebagai 5.\n",
        "    *Classifier* yang sempurna hanya akan memiliki TP dan TN, dengan nilai bukan-nol hanya pada diagonal utamanya.\n",
        "\n",
        "    * **Precision (*Presisi*):** Akurasi prediksi positif.\n",
        "        $$\\text{precision} = \\frac{TP}{TP+FP}$$\n",
        "        Precision tinggi berarti ketika *classifier* mengklaim sesuatu adalah kelas positif, itu sebagian besar benar.\n",
        "    * **Recall (*Sensitivitas* atau *True Positive Rate - TPR*):** Rasio instansi positif yang terdeteksi dengan benar oleh *classifier*.\n",
        "        $$\\text{recall} = \\frac{TP}{TP+FN}$$\n",
        "        Recall tinggi berarti *classifier* menemukan sebagian besar instansi positif.\n",
        "\n",
        "    Contoh perhitungan *precision* dan *recall* untuk *detector*-5:\n",
        "    ```python\n",
        "    from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "    # precision_score(y_train_5, y_train_pred) # Sekitar 0.72908\n",
        "    # recall_score(y_train_5, y_train_pred) # Sekitar 0.75558\n",
        "    ```\n",
        "    Ini menunjukkan bahwa ketika *classifier* mengklaim sebuah gambar adalah 5, itu benar hanya 72.9% dari waktu, dan hanya mendeteksi 75.6% dari angka 5 yang sebenarnya.\n",
        "\n",
        "    * ***F1 Score***:\n",
        "        Metrik gabungan *precision* dan *recall* yang berguna untuk membandingkan *classifier*. Ini adalah *harmonic mean* dari *precision* dan *recall*, yang memberikan bobot lebih pada nilai yang rendah, sehingga *classifier* akan mendapatkan *F1 score* tinggi hanya jika *precision* dan *recall* keduanya tinggi.\n",
        "        $$F_{1}=\\frac{2}{\\frac{1}{precision}+\\frac{1}{recall}}=2\\times\\frac{precision\\times recall}{Precision+recall}=\\frac{TP}{TP+\\frac{FN+FP}{2}}$$\n",
        "    Contoh perhitungan *F1 score*:\n",
        "    ```python\n",
        "    from sklearn.metrics import f1_score\n",
        "\n",
        "    # f1_score(y_train_5, y_train_pred) # Sekitar 0.74209\n",
        "    ```\n",
        "    *F1 score* lebih menyukai *classifier* dengan *precision* dan *recall* yang serupa.\n",
        "\n",
        "* **Precision/Recall Trade-off**:\n",
        "    Meningkatkan *precision* akan mengurangi *recall*, dan sebaliknya. Ini disebut *precision/recall trade-off*. `SGDClassifier` membuat keputusan klasifikasi berdasarkan fungsi keputusan. Jika skor dari fungsi keputusan lebih besar dari ambang batas (*threshold*), instansi ditetapkan ke kelas positif; jika tidak, ke kelas negatif. Menaikkan ambang batas akan meningkatkan *precision* (mengurangi *false positives*) tetapi menurunkan *recall* (meningkatkan *false negatives*). Sebaliknya, menurunkan ambang batas akan meningkatkan *recall* dan mengurangi *precision*.\n",
        "\n",
        "    Scikit-Learn memungkinkan akses ke skor keputusan melalui metode `decision_function()`:\n",
        "    ```python\n",
        "    # y_scores = sgd_clf.decision_function([some_digit]) # Akan menampilkan array([2412.53175101])\n",
        "    # threshold = 0\n",
        "    # y_some_digit_pred = (y_scores > threshold) # Akan menghasilkan array([ True])\n",
        "    # threshold = 8000\n",
        "    # y_some_digit_pred = (y_scores > threshold) # Akan menghasilkan array([False])\n",
        "    ```\n",
        "    Untuk memutuskan ambang batas mana yang akan digunakan, kita bisa mendapatkan skor keputusan untuk semua instansi di *training set* menggunakan `cross_val_predict()` dengan `method=\"decision_function\"`.\n",
        "    ```python\n",
        "    y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,\n",
        "                                 method=\"decision_function\")\n",
        "    ```\n",
        "    Kemudian, `precision_recall_curve()` dapat digunakan untuk menghitung *precision* dan *recall* untuk semua kemungkinan ambang batas.\n",
        "    ```python\n",
        "    from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "    precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n",
        "    ```\n",
        "    Plot *precision* dan *recall* sebagai fungsi dari nilai ambang batas dapat membantu memilih *trade-off* yang sesuai.\n",
        "    ```python\n",
        "    def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "        plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
        "        plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
        "        # Tambahkan kode untuk label dan grid jika perlu\n",
        "        plt.xlabel(\"Threshold\")\n",
        "        plt.legend(loc=\"center left\")\n",
        "        plt.grid(True)\n",
        "\n",
        "    # plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "    # plt.show()\n",
        "    ```\n",
        "    *Precision* mulai menurun tajam sekitar *recall* 80%. Pilihan *trade-off* tergantung pada proyek.\n",
        "    Misalnya, untuk mencapai *precision* 90%:\n",
        "    ```python\n",
        "    threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] # Sekitar ~7816\n",
        "    y_train_pred_90 = (y_scores >= threshold_90_precision)\n",
        "    # precision_score(y_train_5, y_train_pred_90) # Sekitar 0.90003\n",
        "    # recall_score(y_train_5, y_train_pred_90) # Sekitar 0.43681\n",
        "    ```\n",
        "    Menciptakan *classifier* dengan *precision* tinggi cukup mudah dengan mengatur ambang batas yang tinggi, tetapi *recall* yang terlalu rendah membuatnya tidak terlalu berguna.\n",
        "\n",
        "* **The ROC Curve**:\n",
        "    *Receiver Operating Characteristic (ROC) curve* adalah alat umum lain untuk *binary classifier*. Kurva ini memplot *true positive rate* (recall) terhadap *false positive rate* (FPR). FPR adalah rasio instansi negatif yang salah diklasifikasikan sebagai positif, dan sama dengan 1 - *true negative rate* (specificity). Jadi, kurva ROC memplot *sensitivitas* versus 1 - *spesifisitas*.\n",
        "    Untuk memplot kurva ROC, gunakan fungsi `roc_curve()` untuk menghitung TPR dan FPR untuk berbagai nilai ambang batas.\n",
        "    ```python\n",
        "    from sklearn.metrics import roc_curve\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
        "    ```\n",
        "    Plot FPR terhadap TPR:\n",
        "    ```python\n",
        "    def plot_roc_curve(fpr, tpr, label=None):\n",
        "        plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        "        plt.plot([0, 1], [0, 1], 'k--') # Garis diagonal putus-putus untuk classifier acak\n",
        "        plt.xlabel(\"False Positive Rate\")\n",
        "        plt.ylabel(\"True Positive Rate (Recall)\")\n",
        "        plt.grid(True)\n",
        "\n",
        "    # plot_roc_curve(fpr, tpr)\n",
        "    # plt.show()\n",
        "    ```\n",
        "    Ada *trade-off* lain: semakin tinggi *recall* (TPR), semakin banyak *false positives* (FPR) yang dihasilkan *classifier*. *Classifier* yang baik akan menjauh dari garis diagonal (menuju sudut kiri atas).\n",
        "    * **Area Under the Curve (AUC)**:\n",
        "        Salah satu cara membandingkan *classifier* adalah dengan mengukur *Area Under the Curve* (AUC). *Classifier* sempurna memiliki ROC AUC 1, sedangkan *classifier* acak murni memiliki ROC AUC 0.5.\n",
        "    ```python\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "\n",
        "    # roc_auc_score(y_train_5, y_scores) # Sekitar 0.96117\n",
        "    ```\n",
        "    Sebagai aturan umum, pilih kurva PR (*precision/recall*) jika kelas positif jarang atau jika *false positives* lebih penting daripada *false negatives*. Jika tidak, gunakan kurva ROC.\n",
        "\n",
        "    Membandingkan `RandomForestClassifier` dengan `SGDClassifier`:\n",
        "    `RandomForestClassifier` tidak memiliki metode `decision_function()`, tetapi memiliki metode `predict_proba()` yang mengembalikan probabilitas bahwa suatu instansi termasuk dalam kelas tertentu.\n",
        "    ```python\n",
        "    from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "    forest_clf = RandomForestClassifier(random_state=42)\n",
        "    y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
        "                                         method=\"predict_proba\")\n",
        "    y_scores_forest = y_probas_forest[:, 1] # Skor probabilitas kelas positif\n",
        "    fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\n",
        "\n",
        "    # plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
        "    # plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
        "    # plt.legend(loc=\"lower right\")\n",
        "    # plt.show()\n",
        "    ```\n",
        "    Kurva ROC `RandomForestClassifier` terlihat jauh lebih baik, lebih dekat ke sudut kiri atas, dan memiliki skor ROC AUC yang jauh lebih baik.\n",
        "    ```python\n",
        "    # roc_auc_score(y_train_5, y_scores_forest) # Sekitar 0.99834\n",
        "    ```\n",
        "    *Precision* dan *recall* untuk `RandomForestClassifier` ini adalah sekitar 99.0% *precision* dan 86.6% *recall*.\n",
        "\n",
        "**Klasifikasi Multikelas (*Multiclass Classification*)**\n",
        "*Multiclass classifier* membedakan lebih dari dua kelas. Beberapa algoritma (seperti *SGD classifiers*, *Random Forest classifiers*, *naive Bayes classifiers*) dapat menangani banyak kelas secara native. Algoritma lain (seperti *Logistic Regression* atau *Support Vector Machine classifiers*) adalah *binary classifier* ketat.\n",
        "Ada beberapa strategi untuk melakukan klasifikasi multikelas dengan *binary classifier*:\n",
        "* ***One-versus-the-rest (OvR)*** atau ***One-versus-all***: Melatih N *binary classifier*, satu untuk setiap kelas. Saat mengklasifikasikan gambar, ambil skor keputusan dari setiap *classifier* dan pilih kelas dengan skor tertinggi.\n",
        "* ***One-versus-one (OvO)***: Melatih *binary classifier* untuk setiap pasangan digit. Jika ada N kelas, dibutuhkan $N \\times (N-1)/2$ *classifier*. Keuntungan OvO adalah setiap *classifier* hanya perlu dilatih pada bagian *training set* untuk dua kelas yang harus dibedakannya. OvO lebih disukai untuk algoritma yang tidak berskala baik dengan ukuran *training set* (misalnya *Support Vector Machine classifiers*).\n",
        "\n",
        "Scikit-Learn secara otomatis mendeteksi ketika Anda mencoba menggunakan algoritma klasifikasi biner untuk tugas klasifikasi multikelas dan secara otomatis menjalankan OvR atau OvO, tergantung pada algoritmanya.\n",
        "Contoh dengan `SVC` (Support Vector Machine classifier):\n",
        "```python\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_clf = SVC()\n",
        "svm_clf.fit(X_train, y_train) # Menggunakan y_train asli (0-9)\n",
        "# svm_clf.predict([some_digit]) # Akan menampilkan array([5])\n",
        "```\n",
        "Di balik layar, Scikit-Learn menggunakan strategi OvO (melatih 45 *binary classifier*). Metode `decision_function()` akan mengembalikan 10 skor per instansi (satu skor per kelas).\n",
        "```python\n",
        "# some_digit_scores = svm_clf.decision_function([some_digit])\n",
        "# np.argmax(some_digit_scores) # Akan menampilkan 5\n",
        "# svm_clf.classes_ # Menampilkan array ([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
        "```\n",
        "Jika ingin memaksa Scikit-Learn menggunakan OvR atau OvO, gunakan kelas `OneVsOneClassifier` atau `OneVsRestClassifier`.\n",
        "```python\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "ovr_clf = OneVsRestClassifier(SVC())\n",
        "ovr_clf.fit(X_train, y_train)\n",
        "# ovr_clf.predict([some_digit]) # Akan menampilkan array([5])\n",
        "# len(ovr_clf.estimators_) # Akan menampilkan 10\n",
        "```\n",
        "Melatih `SGDClassifier` (atau `RandomForestClassifier`) untuk multikelas lebih mudah karena mereka dapat mengklasifikasikan instansi ke dalam banyak kelas secara langsung.\n",
        "```python\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "# sgd_clf.predict([some_digit]) # Akan menampilkan array([5])\n",
        "# sgd_clf.decision_function([some_digit]) # Akan menampilkan 10 skor untuk setiap kelas\n",
        "```\n",
        "Mengevaluasi akurasi *SGDClassifier* multikelas menggunakan *cross-validation*:\n",
        "```python\n",
        "# cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\") # Sekitar [0.84898, 0.87129, 0.86988]\n",
        "```\n",
        "Skala input dapat meningkatkan akurasi:\n",
        "```python\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
        "# cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\") # Sekitar [0.89707, 0.89609, 0.90693]\n",
        "```\n",
        "\n",
        "**Analisis Kesalahan (*Error Analysis*)**\n",
        "Untuk meningkatkan *classifier*, analisis jenis kesalahan yang dibuatnya.\n",
        "Lihat *confusion matrix* dari *classifier* multikelas:\n",
        "```python\n",
        "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
        "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
        "# conf_mx # Akan menampilkan matriks dengan banyak angka\n",
        "```\n",
        "Representasi visual menggunakan `matshow()` dari Matplotlib lebih mudah dilihat:\n",
        "```python\n",
        "# plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
        "# plt.show()\n",
        "```\n",
        "*Confusion matrix* ini terlihat cukup baik karena sebagian besar gambar berada pada diagonal utama (diklasifikasikan dengan benar). Angka 5 terlihat sedikit lebih gelap, menunjukkan ada lebih sedikit gambar 5 atau *classifier* tidak berkinerja sebaik pada 5.\n",
        "Untuk fokus pada kesalahan, bagi setiap nilai dalam *confusion matrix* dengan jumlah gambar di kelas yang sesuai untuk membandingkan tingkat kesalahan. Kemudian isi diagonal dengan nol.\n",
        "```python\n",
        "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
        "norm_conf_mx = conf_mx / row_sums\n",
        "np.fill_diagonal(norm_conf_mx, 0)\n",
        "# plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
        "# plt.show()\n",
        "```\n",
        "Dari visualisasi ini, terlihat jelas jenis kesalahan yang dibuat *classifier*. Kolom untuk kelas 8 cukup cerah, yang berarti banyak gambar salah diklasifikasikan sebagai 8. Namun, baris untuk kelas 8 tidak terlalu buruk, artinya 8 yang sebenarnya secara umum diklasifikasikan dengan benar. *Confusion matrix* tidak harus simetris. Juga terlihat bahwa 3 dan 5 seringkali saling tertukar.\n",
        "\n",
        "Menganalisis *confusion matrix* memberikan wawasan untuk meningkatkan *classifier*. Misalnya, untuk mengurangi kesalahan pada angka 8, bisa dengan mengumpulkan lebih banyak data pelatihan untuk digit yang mirip 8 tetapi bukan 8, atau menciptakan fitur baru seperti menghitung jumlah lingkaran tertutup. Pra-pemrosesan gambar juga bisa membantu.\n",
        "\n",
        "Menganalisis kesalahan individual juga bermanfaat, meskipun lebih sulit. Misalnya, 3 dan 5 sering salah diklasifikasikan oleh `SGDClassifier` (model linear) karena mereka hanya berbeda beberapa piksel. *Classifier* ini sensitif terhadap pergeseran dan rotasi gambar. Pra-pemrosesan gambar untuk memastikan mereka terpusat dan tidak terlalu berputar dapat mengurangi kebingungan 3/5.\n",
        "\n",
        "**Klasifikasi Multilabel (*Multilabel Classification*)**\n",
        "Dalam *multilabel classification*, *classifier* dapat mengeluarkan beberapa kelas untuk setiap instansi. Contohnya, sistem pengenalan wajah yang mengenali beberapa orang dalam satu gambar akan melampirkan satu tag per orang yang dikenalinya.\n",
        "Contoh sederhana dengan MNIST:\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "y_train_large = (y_train >= 7) # Digit besar (7, 8, atau 9)\n",
        "y_train_odd = (y_train % 2 == 1) # Digit ganjil\n",
        "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
        "\n",
        "knn_clf = KNeighborsClassifier() # Mendukung multilabel classification\n",
        "knn_clf.fit(X_train, y_multilabel)\n",
        "```\n",
        "Prediksi untuk digit 5:\n",
        "```python\n",
        "# knn_clf.predict([some_digit]) # Akan menampilkan array([[False, True]])\n",
        "```\n",
        "Ini benar karena 5 bukan digit besar (False) dan ganjil (True).\n",
        "Untuk mengevaluasi *multilabel classifier*, salah satu pendekatan adalah mengukur *F1 score* untuk setiap label dan menghitung skor rata-rata.\n",
        "```python\n",
        "# y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
        "# f1_score(y_multilabel, y_train_knn_pred, average=\"macro\") # Sekitar 0.97641\n",
        "```\n",
        "`average=\"macro\"` mengasumsikan semua label sama penting. Untuk memberikan bobot berbeda (misalnya berdasarkan *support* label), gunakan `average=\"weighted\"`.\n",
        "\n",
        "**Klasifikasi Multioutput (*Multioutput Classification*)**\n",
        "*Multioutput-multiclass classification* (atau *multioutput classification*) adalah generalisasi dari *multilabel classification* di mana setiap label bisa berupa multikelas (memiliki lebih dari dua nilai).\n",
        "Contohnya adalah sistem penghilang *noise* dari gambar digit. Inputnya adalah gambar digit ber-*noise*, dan outputnya adalah gambar digit bersih, direpresentasikan sebagai array intensitas piksel. Output *classifier* ini adalah multilabel (satu label per piksel) dan setiap label dapat memiliki banyak nilai (intensitas piksel 0-255). Ini adalah contoh sistem klasifikasi *multioutput*.\n",
        "Membangun *training set* dan *test set* dengan menambahkan *noise* pada gambar MNIST:\n",
        "```python\n",
        "noise = np.random.randint(0, 100, (len(X_train), 784))\n",
        "X_train_mod = X_train + noise\n",
        "\n",
        "noise = np.random.randint(0, 100, (len(X_test), 784))\n",
        "X_test_mod = X_test + noise\n",
        "\n",
        "y_train_mod = X_train # Targetnya adalah gambar asli\n",
        "y_test_mod = X_test\n",
        "```\n",
        "Melatih *classifier* untuk membersihkan gambar ini:\n",
        "```python\n",
        "# knn_clf.fit(X_train_mod, y_train_mod)\n",
        "# clean_digit = knn_clf.predict([X_test_mod.iloc[some_index]]) # Menggunakan .iloc karena X_test_mod adalah DataFrame\n",
        "# plot_digit(clean_digit) # Diharapkan menghasilkan gambar digit yang bersih\n",
        "```\n",
        "Ini mengakhiri pembahasan klasifikasi, mencakup pemilihan metrik, *precision/recall trade-off*, perbandingan *classifier*, dan membangun sistem klasifikasi yang baik untuk berbagai tugas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
