{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. Autoencoders**\n",
        "\n",
        "* **Definisi dan Tujuan:** *Autoencoders* adalah jaringan saraf tiruan yang mampu mempelajari representasi padat (disebut *latent representations* atau *codings*) dari data input tanpa pengawasan. *Codings* ini biasanya memiliki dimensionalitas yang jauh lebih rendah daripada data input, sehingga *autoencoders* berguna untuk reduksi dimensionalitas, terutama untuk tujuan visualisasi. *Autoencoders* juga berfungsi sebagai detektor fitur dan dapat digunakan untuk *unsupervised pretraining* pada *deep neural networks*. Beberapa *autoencoders* adalah model generatif, yang mampu menghasilkan data baru secara acak yang sangat mirip dengan data pelatihan. Namun, gambar yang dihasilkan biasanya buram dan kurang realistis.\n",
        "* **Cara Kerja:** *Autoencoders* belajar untuk menyalin input mereka ke output mereka. Hal ini menjadi sulit dengan membatasi jaringan, misalnya, dengan membatasi ukuran *latent representations* atau dengan menambahkan *noise* ke input dan melatih jaringan untuk memulihkan input asli. Batasan ini memaksa *autoencoder* untuk mempelajari cara yang efisien dalam merepresentasikan data.\n",
        "* **Arsitektur:** Sebuah *autoencoder* selalu terdiri dari dua bagian: sebuah *encoder* (atau *recognition network*) yang mengubah input menjadi *latent representation*, diikuti oleh sebuah *decoder* (atau *generative network*) yang mengubah *internal representation* menjadi output. Output sering disebut *reconstructions* karena *autoencoder* mencoba untuk merekonstruksi input, dan *cost function* berisi *reconstruction loss* yang menghukum model ketika *reconstructions* berbeda dari input.\n",
        "* **Jenis-jenis Autoencoder:**\n",
        "    * **Undercomplete Autoencoders:** *Autoencoder* yang *internal representation*-nya memiliki dimensionalitas yang lebih rendah daripada data input. Ini memaksa *autoencoder* untuk mempelajari fitur paling penting dalam data input dan menghilangkan yang tidak penting.\n",
        "        * **PCA dengan Undercomplete Linear Autoencoder:** Jika *autoencoder* hanya menggunakan fungsi aktivasi linier dan *cost function*-nya adalah *mean squared error* (MSE), maka ia akan melakukan *Principal Component Analysis* (PCA).\n",
        "        * **Implementasi:**\n",
        "            ```python\n",
        "            encoder = keras.models.Sequential([keras.layers.Dense(2, input_shape=[3])])\n",
        "            decoder = keras.models.Sequential([keras.layers.Dense(3, input_shape=[2])])\n",
        "            autoencoder = keras.models.Sequential([encoder, decoder])\n",
        "\n",
        "            autoencoder.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=0.1))\n",
        "            history = autoencoder.fit(X_train, X_train, epochs=20)\n",
        "            codings = encoder.predict(X_train)\n",
        "            ```\n",
        "            Kode ini membuat *linear autoencoder* sederhana untuk melakukan PCA pada *dataset* 3D, memproyeksikannya ke 2D. *Encoder* dan *decoder* adalah model `Sequential` dengan satu lapisan `Dense` masing-masing, dan *autoencoder* adalah model `Sequential` yang berisi *encoder* diikuti oleh *decoder*. Output *autoencoder* sama dengan jumlah input, dan tidak ada fungsi aktivasi yang digunakan (semua neuron linier) dengan MSE sebagai *cost function*.\n",
        "    * **Stacked Autoencoders (Deep Autoencoders):** *Autoencoders* dengan beberapa *hidden layers*. Menambahkan lebih banyak lapisan membantu *autoencoder* mempelajari *codings* yang lebih kompleks. Arsitektur biasanya simetris sehubungan dengan *central hidden layer* (*coding layer*).\n",
        "        * **Implementasi:**\n",
        "            ```python\n",
        "            stacked_encoder = keras.models.Sequential([\n",
        "                keras.layers.Flatten(input_shape=[28, 28]),\n",
        "                keras.layers.Dense(100, activation=\"selu\"),\n",
        "                keras.layers.Dense(30, activation=\"selu\"),\n",
        "            ])\n",
        "\n",
        "            stacked_decoder = keras.models.Sequential([\n",
        "                keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "                keras.layers.Dense(28*28, activation=\"sigmoid\"),\n",
        "                keras.layers.Reshape([28, 28])\n",
        "            ])\n",
        "\n",
        "            stacked_ae = keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
        "\n",
        "            stacked_ae.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.SGD(lr=1.5))\n",
        "            history = stacked_ae.fit(X_train, X_train, epochs=10, validation_data=[X_valid, X_valid])\n",
        "            ```\n",
        "            Kode ini membangun *stacked autoencoder* untuk Fashion MNIST. *Encoder* meratakan gambar 28x28 piksel menjadi vektor 784, lalu memprosesnya melalui dua lapisan `Dense` dengan ukuran yang semakin kecil (100 unit kemudian 30 unit) menggunakan fungsi aktivasi SELU. *Decoder* mengambil *codings* ukuran 30, memprosesnya melalui dua lapisan `Dense` dengan ukuran yang semakin besar (100 unit kemudian 784 unit), dan membentuk kembali vektor akhir menjadi larik 28x28. *Binary cross-entropy loss* digunakan karena tugas rekonstruksi diperlakukan sebagai masalah klasifikasi biner multilabel.\n",
        "        * **Tying Weights:** Teknik umum untuk *autoencoder* yang simetris adalah mengikat bobot lapisan *decoder* ke bobot lapisan *encoder*. Ini mengurangi setengah jumlah bobot dalam model, mempercepat pelatihan, dan membatasi risiko *overfitting*.\n",
        "        * **Training One Autoencoder at a Time (Greedy Layerwise Training):** Melatih satu *shallow autoencoder* pada satu waktu, lalu menumpuk semuanya menjadi satu *stacked autoencoder*.\n",
        "    * **Convolutional Autoencoders:** Digunakan untuk gambar. *Encoder* adalah CNN biasa yang terdiri dari *convolutional layers* dan *pooling layers*, yang mengurangi dimensionalitas spasial sambil meningkatkan kedalaman. *Decoder* melakukan hal sebaliknya menggunakan *transpose convolutional layers*.\n",
        "        * **Implementasi:**\n",
        "            ```python\n",
        "            conv_encoder = keras.models.Sequential([\n",
        "                keras.layers.Reshape([28, 28, 1], input_shape=[28, 28]),\n",
        "                keras.layers.Conv2D(16, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "                keras.layers.MaxPool2D(pool_size=2),\n",
        "                keras.layers.Conv2D(32, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "                keras.layers.MaxPool2D(pool_size=2),\n",
        "                keras.layers.Conv2D(64, kernel_size=3, padding=\"same\", activation=\"selu\"),\n",
        "                keras.layers.MaxPool2D(pool_size=2)\n",
        "            ])\n",
        "\n",
        "            conv_decoder = keras.models.Sequential([\n",
        "                keras.layers.Conv2DTranspose(32, kernel_size=3, strides=2, padding=\"valid\",\n",
        "                                            activation=\"selu\", input_shape=[3, 3, 64]),\n",
        "                keras.layers.Conv2DTranspose(16, kernel_size=3, strides=2, padding=\"same\",\n",
        "                                            activation=\"selu\"),\n",
        "                keras.layers.Conv2DTranspose(1, kernel_size=3, strides=2, padding=\"same\",\n",
        "                                            activation=\"sigmoid\"),\n",
        "                keras.layers.Reshape([28, 28])\n",
        "            ])\n",
        "\n",
        "            conv_ae = keras.models.Sequential([conv_encoder, conv_decoder])\n",
        "            ```\n",
        "            *Convolutional autoencoder* ini untuk Fashion MNIST. *Encoder* menggunakan lapisan `Conv2D` dan `MaxPool2D` untuk mengurangi dimensi gambar. *Decoder* menggunakan lapisan `Conv2DTranspose` untuk mengembalikan dimensi gambar ke ukuran aslinya.\n",
        "    * **Recurrent Autoencoders:** Digunakan untuk urutan, seperti *time series* atau teks. *Encoder* biasanya RNN *sequence-to-vector* yang mengompresi *input sequence* menjadi satu vektor. *Decoder* adalah RNN *vector-to-sequence* yang melakukan hal sebaliknya.\n",
        "        * **Implementasi:**\n",
        "            ```python\n",
        "            recurrent_encoder = keras.models.Sequential([\n",
        "                keras.layers.LSTM(100, return_sequences=True, input_shape=[None, 28]),\n",
        "                keras.layers.LSTM(30)\n",
        "            ])\n",
        "\n",
        "            recurrent_decoder = keras.models.Sequential([\n",
        "                keras.layers.RepeatVector(28, input_shape=[30]),\n",
        "                keras.layers.LSTM(100, return_sequences=True),\n",
        "                keras.layers.TimeDistributed(keras.layers.Dense(28, activation=\"sigmoid\"))\n",
        "            ])\n",
        "\n",
        "            recurrent_ae = keras.models.Sequential([recurrent_encoder, recurrent_decoder])\n",
        "            ```\n",
        "            *Recurrent autoencoder* ini dapat memproses urutan dengan panjang berapa pun, dengan 28 dimensi per langkah waktu.\n",
        "    * **Denoising Autoencoders:** Memaksa *autoencoder* untuk mempelajari fitur yang berguna dengan menambahkan *noise* ke inputnya, melatihnya untuk memulihkan input asli yang bebas *noise*. *Noise* bisa berupa *Gaussian noise* murni atau input yang dimatikan secara acak (mirip *dropout*).\n",
        "        * **Implementasi:**\n",
        "            ```python\n",
        "            dropout_encoder = keras.models.Sequential([\n",
        "                keras.layers.Flatten(input_shape=[28, 28]),\n",
        "                keras.layers.Dropout(0.5),\n",
        "                keras.layers.Dense(100, activation=\"selu\"),\n",
        "                keras.layers.Dense(30, activation=\"selu\")\n",
        "            ])\n",
        "\n",
        "            dropout_decoder = keras.models.Sequential([\n",
        "                keras.layers.Dense(100, activation=\"selu\", input_shape=[30]),\n",
        "                keras.layers.Dense(28*28, activation=\"sigmoid\"),\n",
        "                keras.layers.Reshape([28, 28])\n",
        "            ])\n",
        "\n",
        "            dropout_ae = keras.models.Sequential([dropout_encoder, dropout_decoder])\n",
        "            ```\n",
        "            Ini adalah *stacked autoencoder* biasa dengan lapisan `Dropout` tambahan yang diterapkan pada input *encoder*.\n",
        "    * **Sparse Autoencoders:** Menambahkan *term* yang sesuai ke *cost function* untuk mendorong *autoencoder* mengurangi jumlah neuron aktif di *coding layer*. Hal ini memaksa *autoencoder* untuk merepresentasikan setiap input sebagai kombinasi sejumlah kecil aktivasi.\n",
        "        * **L1 Regularization:** Menggunakan fungsi aktivasi *sigmoid* di *coding layer* dan menambahkan *l1 regularization* ke aktivasi *coding layer*.\n",
        "        * **Kullback-Leibler (KL) Divergence:** Mengukur *sparsity* aktual dari *coding layer* pada setiap iterasi pelatihan dan menghukum model ketika *sparsity* yang diukur berbeda dari *target sparsity*. Divergensi KL memiliki *gradients* yang jauh lebih kuat daripada *mean squared error*.\n",
        "        * **Formula KL Divergence:**\n",
        "            $D_{KL}(P||Q)=\\sum_{i}P(i)log\\frac{P(i)}{Q(i)}$\n",
        "            Untuk *target sparsity* $p$ dan *actual sparsity* $q$:\n",
        "            $D_{KL}(p||q)=p~log\\frac{p}{q}+(1-p)log\\frac{1-p}{1-q}$\n",
        "        * **Implementasi KL Divergence Regularizer:**\n",
        "            ```python\n",
        "            K = keras.backend\n",
        "            kl_divergence = keras.losses.kullback_leibler_divergence\n",
        "\n",
        "            class KLDivergenceRegularizer(keras.regularizers.Regularizer):\n",
        "                def __init__(self, weight, target=0.1):\n",
        "                    self.weight = weight\n",
        "                    self.target = target\n",
        "                    super().__init__()\n",
        "\n",
        "                def __call__(self, inputs):\n",
        "                    mean_activities = K.mean(inputs, axis=0)\n",
        "                    return self.weight * (\n",
        "                        kl_divergence(self.target, mean_activities) +\n",
        "                        kl_divergence(1. - self.target, 1. - mean_activities))\n",
        "            ```\n",
        "            Ini adalah *custom regularizer* untuk menerapkan *KL divergence regularization*.\n",
        "    * **Variational Autoencoders (VAEs):** *Probabilistic autoencoders* (outputnya sebagian ditentukan oleh peluang) dan *generative autoencoders* (dapat menghasilkan instance baru yang terlihat seperti sampel dari *training set*). *Encoder* menghasilkan *mean coding* ($\\mu$) dan *standard deviation* ($\\sigma$), dan *coding* sebenarnya diambil secara acak dari distribusi Gaussian dengan *mean* $\\mu$ dan *standard deviation* $\\sigma$.\n",
        "        * **Cost Function VAE:** Terdiri dari dua bagian: *reconstruction loss* (seperti biasa) dan *latent loss* yang mendorong *codings* agar terlihat seperti sampel dari distribusi Gaussian.\n",
        "        * **Formula Latent Loss:**\n",
        "            $\\Theta=-\\frac{1}{2}\\sum_{i=1}^{K}1+log(\\sigma_{i}^{2})-\\sigma_{i}^{2}-\\mu_{i}^{2}$\n",
        "            Atau dengan *tweak* $\\gamma=log(\\sigma^{2})$:\n",
        "            $\\mathcal{Z}=-\\frac{1}{2}\\sum_{i=1}^{K}1+y_{i}-exp(y_{i})-\\mu_{i}^{2}$\n",
        "        * **Implementasi Sampling Layer:**\n",
        "            ```python\n",
        "            class Sampling(keras.layers.Layer):\n",
        "                def call(self, inputs):\n",
        "                    mean, log_var = inputs\n",
        "                    return K.random_normal(tf.shape(log_var)) * K.exp(log_var / 2) + mean\n",
        "            ```\n",
        "            Lapisan `Sampling` ini mengambil `mean` ($\\mu$) dan `log_var` ($\\gamma$) sebagai input. Ia menggunakan `K.random_normal()` untuk mengambil sampel vektor acak dari distribusi Normal dengan *mean* 0 dan *standard deviation* 1, lalu mengalikannya dengan `exp(log_var / 2)` (yang sama dengan $\\sigma$) dan menambahkan `mean` untuk menghasilkan vektor *codings* yang diambil sampelnya dari distribusi Normal dengan *mean* $\\mu$ dan *standard deviation* $\\sigma$.\n",
        "        * **Implementasi VAE:**\n",
        "            ```python\n",
        "            codings_size = 10\n",
        "            inputs = keras.layers.Input(shape=[28, 28])\n",
        "            z = keras.layers.Flatten()(inputs)\n",
        "            z = keras.layers.Dense(150, activation=\"selu\")(z)\n",
        "            z = keras.layers.Dense(100, activation=\"selu\")(z)\n",
        "            codings_mean = keras.layers.Dense(codings_size)(z)\n",
        "            codings_log_var = keras.layers.Dense(codings_size)(z)\n",
        "            codings = Sampling()([codings_mean, codings_log_var])\n",
        "            variational_encoder = keras.Model(\n",
        "                inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])\n",
        "\n",
        "            decoder_inputs = keras.layers.Input(shape=[codings_size])\n",
        "            x = keras.layers.Dense(100, activation=\"selu\")(decoder_inputs)\n",
        "            x = keras.layers.Dense(150, activation=\"selu\")(x)\n",
        "            x = keras.layers.Dense(28*28, activation=\"sigmoid\")(x)\n",
        "            outputs = keras.layers.Reshape([28, 28])(x)\n",
        "            variational_decoder = keras.Model(inputs=[decoder_inputs], outputs=[outputs])\n",
        "\n",
        "            _, _, codings = variational_encoder(inputs)\n",
        "            reconstructions = variational_decoder(codings)\n",
        "            variational_ae = keras.Model(inputs=[inputs], outputs=[reconstructions])\n",
        "\n",
        "            latent_loss = -0.5 * K.sum(\n",
        "                1 + codings_log_var - K.exp(codings_log_var) - K.square(codings_mean),\n",
        "                axis=-1)\n",
        "            variational_ae.add_loss(K.mean(latent_loss) / 784.)\n",
        "            variational_ae.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "            ```\n",
        "            Kode ini membuat *variational autoencoder* menggunakan *Functional API*. *Encoder* menghasilkan *mean* dan *log_var* dari *codings*, yang kemudian digunakan oleh lapisan `Sampling` untuk menghasilkan *codings* aktual. *Decoder* kemudian merekonstruksi gambar dari *codings*. *Latent loss* dan *reconstruction loss* ditambahkan ke model.\n",
        "\n",
        "**2. Generative Adversarial Networks (GANs)**\n",
        "\n",
        "* **Definisi dan Tujuan:** GANs diperkenalkan pada tahun 2014. Mereka terdiri dari dua jaringan saraf yang bersaing satu sama lain: sebuah *generator* dan sebuah *discriminator*. GANs sangat efektif dalam menghasilkan data baru yang sangat realistis, terutama gambar.\n",
        "* **Komponen GAN:**\n",
        "    * **Generator:** Mengambil distribusi acak sebagai input (biasanya Gaussian) dan menghasilkan beberapa data, biasanya gambar. Input acak dapat dianggap sebagai *latent representations* atau *codings* dari gambar yang akan dihasilkan. Tujuannya adalah untuk \"menipu\" *discriminator*.\n",
        "    * **Discriminator:** Mengambil gambar palsu dari *generator* atau gambar asli dari *training set* sebagai input, dan harus menebak apakah gambar input itu palsu atau asli. Tujuannya adalah untuk \"memberi tahu\" mana yang palsu dan mana yang asli.\n",
        "* **Proses Pelatihan:**\n",
        "    * **Fase 1 (Melatih Discriminator):** Sebuah *batch* gambar asli diambil dari *training set* dan dilengkapi dengan jumlah gambar palsu yang sama yang dihasilkan oleh *generator*. Label diatur ke 0 untuk gambar palsu dan 1 untuk gambar asli. *Discriminator* dilatih pada *batch* berlabel ini untuk satu langkah, menggunakan *binary cross-entropy loss*. Selama fase ini, hanya bobot *discriminator* yang dioptimalkan.\n",
        "    * **Fase 2 (Melatih Generator):** *Generator* digunakan untuk menghasilkan *batch* gambar palsu lainnya. *Discriminator* digunakan untuk memberi tahu apakah gambar-gambar ini palsu atau asli. Kali ini, semua label diatur ke 1 (asli) karena tujuan *generator* adalah membuat *discriminator* percaya bahwa gambar-gambar palsu itu asli. Bobot *discriminator* dibekukan selama langkah ini, sehingga *backpropagation* hanya memengaruhi bobot *generator*.\n",
        "* **Implementasi Sederhana GAN:**\n",
        "    ```python\n",
        "    codings_size = 30\n",
        "    generator = keras.models.Sequential([\n",
        "        keras.layers.Dense(100, activation=\"selu\", input_shape=[codings_size]),\n",
        "        keras.layers.Dense(150, activation=\"selu\"),\n",
        "        keras.layers.Dense(28*28, activation=\"sigmoid\"),\n",
        "        keras.layers.Reshape([28, 28])\n",
        "    ])\n",
        "\n",
        "    discriminator = keras.models.Sequential([\n",
        "        keras.layers.Flatten(input_shape=[28, 28]),\n",
        "        keras.layers.Dense(150, activation=\"selu\"),\n",
        "        keras.layers.Dense(100, activation=\"selu\"),\n",
        "        keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    ])\n",
        "\n",
        "    gan = keras.models.Sequential([generator, discriminator])\n",
        "\n",
        "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "    discriminator.trainable = False\n",
        "    gan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\n",
        "\n",
        "    batch_size = 32\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(X_train).shuffle(1000)\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n",
        "\n",
        "    def train_gan(gan, dataset, batch_size, codings_size, n_epochs=50):\n",
        "        generator, discriminator = gan.layers\n",
        "        for epoch in range(n_epochs):\n",
        "            for X_batch in dataset:\n",
        "                # phase 1 - training the discriminator\n",
        "                noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "                generated_images = generator(noise)\n",
        "                X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n",
        "                y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n",
        "                discriminator.trainable = True\n",
        "                discriminator.train_on_batch(X_fake_and_real, y1)\n",
        "\n",
        "                # phase 2 - training the generator\n",
        "                noise = tf.random.normal(shape=[batch_size, codings_size])\n",
        "                y2 = tf.constant([[1.]] * batch_size)\n",
        "                discriminator.trainable = False\n",
        "                gan.train_on_batch(noise, y2)\n",
        "\n",
        "    train_gan(gan, dataset, batch_size, codings_size)\n",
        "    ```\n",
        "    *Generator* mirip dengan *decoder autoencoder*, dan *discriminator* adalah *binary classifier*. *Binary cross-entropy loss* digunakan untuk *discriminator* dan model GAN. Selama fase pelatihan *generator*, *discriminator* dibuat *non-trainable*.\n",
        "* **Kesulitan dalam Melatih GANs:**\n",
        "    * **Mode Collapse:** Output *generator* secara bertahap menjadi kurang beragam. *Generator* mungkin menjadi sangat baik dalam menghasilkan satu jenis output (misalnya, sepatu) dan melupakan cara menghasilkan jenis lainnya.\n",
        "    * **Ketidakstabilan Pelatihan:** Parameter *generator* dan *discriminator* dapat berosilasi dan menjadi tidak stabil. Pelatihan dapat tiba-tiba menyimpang tanpa alasan yang jelas.\n",
        "    * **Sensitivitas Hiperparameter:** GANs sangat sensitif terhadap *hyperparameter*.\n",
        "* **Teknik untuk Mengatasi Kesulitan:**\n",
        "    * **Experience Replay:** Menyimpan gambar yang dihasilkan oleh *generator* pada setiap iterasi dalam *replay buffer* dan melatih *discriminator* menggunakan gambar asli ditambah gambar palsu dari *buffer* ini. Ini mengurangi kemungkinan *discriminator* melakukan *overfit* pada output *generator* terbaru.\n",
        "    * **Mini-batch Discrimination:** Mengukur seberapa mirip gambar di seluruh *batch* dan memberikan *statistic* ini ke *discriminator*, sehingga dapat dengan mudah menolak seluruh *batch* gambar palsu yang kurang beragam. Ini mendorong *generator* untuk menghasilkan variasi gambar yang lebih besar, mengurangi risiko *mode collapse*.\n",
        "* **Arsitektur GAN yang Berhasil:**\n",
        "    * **Deep Convolutional GANs (DCGANs):** DCGANs menggunakan pedoman tertentu untuk membangun GANs *convolutional* yang stabil: mengganti *pooling layers* dengan *strided convolutions* (di *discriminator*) dan *transposed convolutions* (di *generator*), menggunakan *Batch Normalization* (kecuali di lapisan output *generator* dan lapisan input *discriminator*), menghapus *fully connected hidden layers* untuk arsitektur yang lebih dalam, menggunakan aktivasi ReLU di *generator* (kecuali lapisan output yang menggunakan tanh), dan menggunakan aktivasi *leaky ReLU* di *discriminator*.\n",
        "        * **Implementasi DCGAN:**\n",
        "            ```python\n",
        "            codings_size = 100\n",
        "            generator = keras.models.Sequential([\n",
        "                keras.layers.Dense(7 * 7 * 128, input_shape=[codings_size]),\n",
        "                keras.layers.Reshape([7, 7, 128]),\n",
        "                keras.layers.BatchNormalization(),\n",
        "                keras.layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                            activation=\"selu\"),\n",
        "                keras.layers.BatchNormalization(),\n",
        "                keras.layers.Conv2DTranspose(1, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                            activation=\"tanh\")\n",
        "            ])\n",
        "\n",
        "            discriminator = keras.models.Sequential([\n",
        "                keras.layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                    activation=keras.layers.LeakyReLU(0.2),\n",
        "                                    input_shape=[28, 28, 1]),\n",
        "                keras.layers.Dropout(0.4),\n",
        "                keras.layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\",\n",
        "                                    activation=keras.layers.LeakyReLU(0.2)),\n",
        "                keras.layers.Dropout(0.4),\n",
        "                keras.layers.Flatten(),\n",
        "                keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "            ])\n",
        "\n",
        "            gan = keras.models.Sequential([generator, discriminator])\n",
        "            ```\n",
        "            *Generator* memproyeksikan *codings* ke tensor yang kemudian di-*upsample* oleh *transpose convolutional layers*. *Discriminator* menggunakan *strided convolutions* alih-alih *max pooling* dan fungsi aktivasi *leaky ReLU*.\n",
        "        * **Conditional GAN (CGAN):** Menambahkan kelas gambar sebagai input tambahan ke *generator* dan *discriminator*, memungkinkan kontrol atas kelas gambar yang dihasilkan.\n",
        "    * **Progressive Growing of GANs:** Menghasilkan gambar kecil di awal pelatihan, lalu secara bertahap menambahkan *convolutional layers* ke *generator* dan *discriminator* untuk menghasilkan gambar yang semakin besar. Teknik ini menggunakan *fade-in/fade-out* saat menambahkan lapisan baru.\n",
        "        * **Minibatch Standard Deviation Layer:** Ditambahkan di dekat akhir *discriminator*, menghitung *standard deviation* di seluruh *channel* dan *instance* dalam *batch*. Ini membantu *discriminator* mendeteksi kurangnya variasi dalam gambar yang dihasilkan, mendorong *generator* untuk menghasilkan output yang lebih beragam.\n",
        "        * **Equalized Learning Rate:** Menginisialisasi semua bobot menggunakan distribusi Gaussian sederhana, tetapi menskalakan bobot ke bawah saat *runtime*. Ini memastikan bahwa *dynamic range* sama untuk semua parameter, mempercepat dan menstabilkan pelatihan.\n",
        "        * **Pixelwise Normalization Layer:** Ditambahkan setelah setiap *convolutional layer* di *generator*. Ini menormalisasi setiap aktivasi berdasarkan semua aktivasi di gambar yang sama dan lokasi yang sama, tetapi di semua *channel*. Teknik ini menghindari ledakan dalam aktivasi karena persaingan yang berlebihan antara *generator* dan *discriminator*.\n",
        "    * **StyleGANs:** Memajukan *state of the art* dalam generasi gambar resolusi tinggi menggunakan teknik *style transfer* di *generator*.\n",
        "        * **Mapping Network:** Sebuah MLP delapan lapisan yang memetakan *latent representations* $z$ ke vektor $w$. Vektor ini kemudian dikirim melalui beberapa transformasi *affine* untuk menghasilkan banyak vektor yang mengontrol *style* gambar yang dihasilkan pada tingkat yang berbeda.\n",
        "        * **Synthesis Network:** Bertanggung jawab untuk menghasilkan gambar. Ia memiliki input *constant learned* dan memprosesnya melalui beberapa lapisan *convolutional* dan *upsampling*. *Noise* ditambahkan ke input dan semua output lapisan *convolutional*. Setiap lapisan *noise* diikuti oleh lapisan *Adaptive Instance Normalization* (AdaIN) yang menstandardisasi setiap *feature map* secara independen dan menggunakan vektor *style* untuk menentukan skala dan offset setiap *feature map*.\n",
        "        * **Mixing Regularization (Style Mixing):** Persentase gambar yang dihasilkan diproduksi menggunakan dua *codings* yang berbeda. Hal ini mencegah jaringan berasumsi bahwa *style* pada tingkat yang berdekatan berkorelasi, mendorong *locality* dalam GAN."
      ],
      "metadata": {
        "id": "28Zjlb-fwDTH"
      }
    }
  ]
}